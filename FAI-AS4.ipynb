{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on MNIST (Task 1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:02<00:00, 389.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Accuracy on MNIST after training: 0.88\n",
      "\n",
      "Training on Fashion-MNIST (Task 2) without EWC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:02<00:00, 405.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Fashion-MNIST (Task 2) without EWC: 0.80\n",
      "Retained Accuracy on MNIST without EWC: 0.09\n",
      "\n",
      "Training on Fashion-MNIST (Task 2) with EWC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:02<00:00, 313.48it/s]\n",
      "100%|██████████| 938/938 [00:02<00:00, 333.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Fashion-MNIST with EWC: 0.81\n",
      "Retained Accuracy on MNIST with EWC: 0.52\n",
      "\n",
      "--- Comparison Summary ---\n",
      "MNIST Accuracy after Fashion-MNIST (without EWC): 0.09\n",
      "MNIST Accuracy after Fashion-MNIST (with EWC): 0.52\n",
      "Fashion-MNIST Accuracy (without EWC): 0.80\n",
      "Fashion-MNIST Accuracy (with EWC): 0.81\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=100, num_classes=10):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  #Flatten the input\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# EWC Implementation\n",
    "class EWC:\n",
    "    def __init__(self, model, dataloader, device='cpu'):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n",
    "        self._means = {n: p.clone().detach() for n, p in self.params.items()}\n",
    "        self._fisher = self._compute_fisher_information()\n",
    "\n",
    "    def _compute_fisher_information(self):\n",
    "        fisher = {n: torch.zeros_like(p) for n, p in self.params.items()}\n",
    "        self.model.eval()\n",
    "        for x, y in self.dataloader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            self.model.zero_grad()\n",
    "            output = self.model(x)\n",
    "            loss = nn.functional.cross_entropy(output, y)\n",
    "            loss.backward()\n",
    "            for n, p in self.params.items():\n",
    "                fisher[n] += p.grad ** 2 / len(self.dataloader)\n",
    "        fisher = {n: p.clone().detach() for n, p in fisher.items()}\n",
    "        return fisher\n",
    "\n",
    "    def penalty(self, model):\n",
    "        loss = 0\n",
    "        for n, p in model.named_parameters():\n",
    "            if n in self._fisher:\n",
    "                _loss = self._fisher[n] * (p - self._means[n]) ** 2\n",
    "                loss += _loss.sum()\n",
    "        return loss\n",
    "\n",
    "# Training function with EWC\n",
    "def train(model, dataloader, optimizer, ewc=None, ewc_lambda=0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = nn.functional.cross_entropy(output, y)\n",
    "        if ewc:\n",
    "            loss += ewc_lambda * ewc.penalty(model)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            _, pred = output.max(1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "    return correct / len(dataloader.dataset)\n",
    "\n",
    "# Dataset and model setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "fashion_mnist = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "mnist_loader = DataLoader(mnist, batch_size=64, shuffle=True)\n",
    "fashion_loader = DataLoader(fashion_mnist, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model, optimizer, and EWC setup\n",
    "model = SimpleNN().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "def reset_model_weights(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "# Train on Task 1 (MNIST) without EWC\n",
    "print(\"Training on MNIST (Task 1)...\")\n",
    "reset_model_weights(model)  # Ensure model starts from scratch\n",
    "train(model, mnist_loader, optimizer)\n",
    "mnist_acc_initial = evaluate(model, mnist_loader)\n",
    "print(f\"Initial Accuracy on MNIST after training: {mnist_acc_initial:.2f}\")\n",
    "\n",
    "# Save the EWC data for MNIST for later use\n",
    "ewc_mnist = EWC(model, mnist_loader, device=device)\n",
    "\n",
    "# Train on Task 2 (Fashion-MNIST) without EWC\n",
    "print(\"\\nTraining on Fashion-MNIST (Task 2) without EWC...\")\n",
    "reset_model_weights(model)  #Reset weights\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "train(model, fashion_loader, optimizer)  \n",
    "fashion_mnist_acc_no_ewc = evaluate(model, fashion_loader)\n",
    "mnist_acc_no_ewc = evaluate(model, mnist_loader)\n",
    "print(f\"Accuracy on Fashion-MNIST (Task 2) without EWC: {fashion_mnist_acc_no_ewc:.2f}\")\n",
    "print(f\"Retained Accuracy on MNIST without EWC: {mnist_acc_no_ewc:.2f}\")\n",
    "\n",
    "# Train on Task 2 (Fashion-MNIST) with EWC\n",
    "ewc_lambda = 0.4\n",
    "print(\"\\nTraining on Fashion-MNIST (Task 2) with EWC...\")\n",
    "reset_model_weights(model)  #Reset weights\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "train(model, mnist_loader, optimizer)  #First, train on MNIST to set up EWC\n",
    "train(model, fashion_loader, optimizer, ewc=ewc_mnist, ewc_lambda=ewc_lambda)  #Train with EWC\n",
    "fashion_mnist_acc_with_ewc = evaluate(model, fashion_loader)\n",
    "mnist_acc_with_ewc = evaluate(model, mnist_loader)\n",
    "print(f\"Accuracy on Fashion-MNIST with EWC: {fashion_mnist_acc_with_ewc:.2f}\")\n",
    "print(f\"Retained Accuracy on MNIST with EWC: {mnist_acc_with_ewc:.2f}\")\n",
    "\n",
    "# Summary of Results\n",
    "print(\"\\n--- Comparison Summary ---\")\n",
    "print(f\"MNIST Accuracy after Fashion-MNIST (without EWC): {mnist_acc_no_ewc:.2f}\")\n",
    "print(f\"MNIST Accuracy after Fashion-MNIST (with EWC): {mnist_acc_with_ewc:.2f}\")\n",
    "print(f\"Fashion-MNIST Accuracy (without EWC): {fashion_mnist_acc_no_ewc:.2f}\")\n",
    "print(f\"Fashion-MNIST Accuracy (with EWC): {fashion_mnist_acc_with_ewc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
